#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§å‹æäº¤å®¡æŸ¥é—®é¢˜è¯Šæ–­å·¥å…·
ç”¨äºåˆ†æå’Œè§£å†³å®¡æŸ¥ç»“æœä¸å®Œæ•´çš„é—®é¢˜
"""

import os
import sys
import json
import argparse
from datetime import datetime, timedelta

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
src_path = os.path.join(parent_dir, 'src')
sys.path.insert(0, src_path)

from config_manager import ConfigManager


class CommitAnalyzer:
    """æäº¤åˆ†æå™¨"""
    
    def __init__(self):
        self.config = ConfigManager()
        
    def analyze_commit_size(self, revision):
        """åˆ†ææŒ‡å®šæäº¤çš„å¤§å°å’Œå¤æ‚åº¦"""
        print(f"\nğŸ” åˆ†ææäº¤ {revision} çš„è¯¦ç»†ä¿¡æ¯...")
        
        # è·å–diffå†…å®¹
        diff_content = self._get_commit_diff(revision)
        
        if not diff_content or diff_content.startswith("è·å–å·®å¼‚å¤±è´¥"):
            print(f"âŒ æ— æ³•è·å–æäº¤ {revision} çš„å·®å¼‚å†…å®¹")
            return None
        
        # åˆ†ædiffå†…å®¹
        analysis = self._analyze_diff_content(diff_content)
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        changed_files = self._get_changed_files(revision)
        
        # è¾“å‡ºåˆ†æç»“æœ
        print(f"\nğŸ“Š æäº¤ {revision} åˆ†æç»“æœ:")
        print(f"{'='*50}")
        print(f"ğŸ“ æ€»å­—ç¬¦æ•°: {analysis['total_chars']:,}")
        print(f"ğŸ“„ æ€»è¡Œæ•°: {analysis['total_lines']:,}")
        print(f"â• æ–°å¢è¡Œæ•°: {analysis['added_lines']:,}")
        print(f"â– åˆ é™¤è¡Œæ•°: {analysis['deleted_lines']:,}")
        print(f"ğŸ“ ä¿®æ”¹æ–‡ä»¶æ•°: {len(changed_files)}")
        print(f"ğŸ”¢ å½“å‰æˆªæ–­é•¿åº¦: 8000 å­—ç¬¦")
        print(f"ğŸ’” æˆªæ–­ä¸¢å¤±ç‡: {((analysis['total_chars'] - 8000) / analysis['total_chars'] * 100):.1f}%" 
              if analysis['total_chars'] > 8000 else "0%")
        
        # æŒ‰æ–‡ä»¶ç±»å‹åˆ†æ
        file_types = {}
        for file_info in changed_files:
            path = file_info.get('path', '')
            ext = os.path.splitext(path)[1].lower()
            if not ext:
                ext = '(æ— æ‰©å±•å)'
            file_types[ext] = file_types.get(ext, 0) + 1
        
        print(f"\nğŸ“ ä¿®æ”¹æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
        for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True):
            print(f"  {ext}: {count} ä¸ªæ–‡ä»¶")
        
        # å»ºè®®é…ç½®
        print(f"\nğŸ’¡ å»ºè®®é…ç½®:")
        if analysis['total_chars'] > 8000:
            suggested_limit = min(analysis['total_chars'] + 5000, 50000)
            print(f"  ğŸ“ å»ºè®®diffæˆªæ–­é•¿åº¦: {suggested_limit:,} å­—ç¬¦")
        else:
            print(f"  âœ… å½“å‰æˆªæ–­é•¿åº¦å·²è¶³å¤Ÿ")
        
        # Tokenä¼°ç®—
        estimated_tokens = analysis['total_chars'] // 3  # ç²—ç•¥ä¼°ç®—
        if estimated_tokens > 2000:
            suggested_max_tokens = min(estimated_tokens + 1000, 8000)
            print(f"  ğŸ¯ å»ºè®®max_tokens: {suggested_max_tokens}")
        else:
            print(f"  âœ… å½“å‰max_tokenså·²è¶³å¤Ÿ")
        
        return analysis
    
    def _get_commit_diff(self, revision):
        """è·å–æäº¤çš„å®Œæ•´diffå†…å®¹"""
        import subprocess
        
        repository_url = self.config.config['svn']['repository_url']
        username = self.config.config['svn']['username'] 
        password = self.config.config['svn']['password']
        
        try:
            cmd = [
                'svn', 'diff',
                f'{repository_url}',
                f'-c{revision}',
                '--username', username,
                '--password', password,
                '--non-interactive',
                '--trust-server-cert'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True,
                                  encoding='utf-8', timeout=180)
            
            if result.returncode == 0:
                return result.stdout
            else:
                return f"è·å–å·®å¼‚å¤±è´¥: {result.stderr}"
                
        except Exception as e:
            return f"è·å–å·®å¼‚å¼‚å¸¸: {e}"
    
    def _get_changed_files(self, revision):
        """è·å–æŒ‡å®šç‰ˆæœ¬çš„å˜æ›´æ–‡ä»¶åˆ—è¡¨"""
        import subprocess
        import xml.etree.ElementTree as ET
        
        repository_url = self.config.config['svn']['repository_url']
        username = self.config.config['svn']['username']
        password = self.config.config['svn']['password']
        
        try:
            cmd = [
                'svn', 'log',
                repository_url,
                f'-r{revision}',
                '--xml',
                '--verbose',
                '--username', username,
                '--password', password,
                '--non-interactive',
                '--trust-server-cert'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True,
                                  encoding='utf-8', timeout=60)
            
            if result.returncode == 0:
                root = ET.fromstring(result.stdout)
                logentry = root.find('logentry')
                changed_files = []
                
                if logentry is not None:
                    paths = logentry.find('paths')
                    if paths is not None:
                        for path in paths.findall('path'):
                            file_info = {
                                'path': path.text,
                                'action': path.get('action', ''),
                                'kind': path.get('kind', 'file')
                            }
                            changed_files.append(file_info)
                
                return changed_files
            else:
                print(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {result.stderr}")
                return []
                
        except Exception as e:
            print(f"è·å–æ–‡ä»¶åˆ—è¡¨å¼‚å¸¸: {e}")
            return []
    
    def _analyze_diff_content(self, diff_content):
        """åˆ†ædiffå†…å®¹çš„ç»Ÿè®¡ä¿¡æ¯"""
        lines = diff_content.split('\n')
        total_lines = len(lines)
        total_chars = len(diff_content)
        
        added_lines = 0
        deleted_lines = 0
        
        for line in lines:
            if line.startswith('+') and not line.startswith('+++'):
                added_lines += 1
            elif line.startswith('-') and not line.startswith('---'):
                deleted_lines += 1
        
        return {
            'total_chars': total_chars,
            'total_lines': total_lines,
            'added_lines': added_lines,
            'deleted_lines': deleted_lines
        }
    
    def suggest_optimizations(self, revision_list):
        """å¯¹å¤šä¸ªæäº¤åˆ†æå¹¶æä¾›ä¼˜åŒ–å»ºè®®"""
        print(f"\nğŸ¯ åˆ†æ {len(revision_list)} ä¸ªæäº¤ï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        
        total_analysis = {
            'total_commits': len(revision_list),
            'large_commits': 0,  # è¶…è¿‡8000å­—ç¬¦çš„æäº¤
            'max_chars': 0,
            'avg_chars': 0,
            'max_tokens_needed': 2000,
            'diff_limit_needed': 8000
        }
        
        char_counts = []
        
        for revision in revision_list:
            analysis = self.analyze_commit_size(revision)
            if analysis:
                chars = analysis['total_chars']
                char_counts.append(chars)
                
                if chars > total_analysis['max_chars']:
                    total_analysis['max_chars'] = chars
                
                if chars > 8000:
                    total_analysis['large_commits'] += 1
        
        if char_counts:
            total_analysis['avg_chars'] = sum(char_counts) // len(char_counts)
        
        # è®¡ç®—å»ºè®®å€¼
        if total_analysis['max_chars'] > 8000:
            total_analysis['diff_limit_needed'] = min(
                total_analysis['max_chars'] + 10000, 
                100000  # æœ€å¤§é™åˆ¶
            )
        
        estimated_max_tokens = total_analysis['max_chars'] // 3
        if estimated_max_tokens > 2000:
            total_analysis['max_tokens_needed'] = min(
                estimated_max_tokens + 2000,
                16000  # æœ€å¤§é™åˆ¶
            )
        
        # è¾“å‡ºæ€»ä½“å»ºè®®
        print(f"\nğŸ¯ æ€»ä½“ä¼˜åŒ–å»ºè®®:")
        print(f"{'='*50}")
        print(f"ğŸ“Š åˆ†æäº† {total_analysis['total_commits']} ä¸ªæäº¤")
        print(f"ğŸ”¥ å¤§å‹æäº¤æ•°é‡: {total_analysis['large_commits']} ä¸ª "
              f"({total_analysis['large_commits']/total_analysis['total_commits']*100:.1f}%)")
        print(f"ğŸ“ æœ€å¤§å­—ç¬¦æ•°: {total_analysis['max_chars']:,}")
        print(f"ğŸ“Š å¹³å‡å­—ç¬¦æ•°: {total_analysis['avg_chars']:,}")
        
        print(f"\nâš™ï¸  å»ºè®®é…ç½®æ›´æ–°:")
        print(f"  ai.diff_limit: {total_analysis['diff_limit_needed']:,}  # å½“å‰: 8000")
        print(f"  ai.max_tokens: {total_analysis['max_tokens_needed']}  # å½“å‰: 2000")
        
        if total_analysis['large_commits'] > 0:
            print(f"\nâš ï¸  è­¦å‘Š: å‘ç° {total_analysis['large_commits']} ä¸ªå¤§å‹æäº¤")
            print(f"   è¿™äº›æäº¤çš„å†…å®¹å¯èƒ½è¢«æˆªæ–­ï¼Œå½±å“å®¡æŸ¥è´¨é‡ï¼")
        
        return total_analysis


def main():
    parser = argparse.ArgumentParser(description='å¤§å‹æäº¤å®¡æŸ¥é—®é¢˜è¯Šæ–­å·¥å…·')
    parser.add_argument('revisions', nargs='+', help='è¦åˆ†æçš„æäº¤ç‰ˆæœ¬å·')
    parser.add_argument('--suggest', action='store_true', 
                       help='ç”Ÿæˆä¼˜åŒ–å»ºè®®')
    
    args = parser.parse_args()
    
    analyzer = CommitAnalyzer()
    
    if args.suggest:
        analyzer.suggest_optimizations(args.revisions)
    else:
        for revision in args.revisions:
            analyzer.analyze_commit_size(revision)


if __name__ == '__main__':
    main()
